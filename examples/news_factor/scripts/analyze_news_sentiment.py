#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°é—»æƒ…æ„Ÿåˆ†æè„šæœ¬
ä½¿ç”¨DeepSeek APIå¯¹æ–°é—»æ•°æ®è¿›è¡Œæƒ…æ„Ÿåˆ†æ
"""

import pandas as pd
import sys
import time
import json
import os
from pathlib import Path
from openai import OpenAI
from tqdm import tqdm
import argparse
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æŠ‘åˆ¶HTTPè¯·æ±‚æ—¥å¿—ï¼Œåªæ˜¾ç¤ºè¿›åº¦æ¡
import logging
logging.getLogger("openai").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

# DeepSeek APIé…ç½® - ä».envæ–‡ä»¶è¯»å–
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
DEEPSEEK_BASE_URL = os.getenv('DEEPSEEK_BASE_URL', "https://api.deepseek.com/v1")
MODEL = os.getenv('DEEPSEEK_MODEL', "deepseek-chat")

class NewsAnalyzer:
    def __init__(self):
        self.client = OpenAI(
            api_key=DEEPSEEK_API_KEY,
            base_url=DEEPSEEK_BASE_URL
        )
        
    def analyze_sentiment(self, text: str) -> dict:
        """åˆ†æå•æ¡æ–°é—»çš„æƒ…æ„Ÿ"""
        prompt = f"""è¯·å¯¹ä»¥ä¸‹åŠ å¯†è´§å¸æ–°é—»è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼š

æ–°é—»å†…å®¹: {text}

è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
- sentiment_score: -1åˆ°1çš„æ•°å€¼ï¼ˆ-1æåº¦è´Ÿé¢ï¼Œ0ä¸­æ€§ï¼Œ1æåº¦æ­£é¢ï¼‰  
- confidence: 0åˆ°1çš„ç½®ä¿¡åº¦
- sentiment_label: "è´Ÿé¢"/"ä¸­æ€§"/"æ­£é¢"
- market_impact: "åˆ©ç©º"/"ä¸­æ€§"/"åˆ©å¥½"

ç¤ºä¾‹æ ¼å¼ï¼š
{{"sentiment_score": 0.5, "confidence": 0.8, "sentiment_label": "æ­£é¢", "market_impact": "åˆ©å¥½"}}"""
        
        try:
            response = self.client.chat.completions.create(
                model=MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=200
            )
            
            content = response.choices[0].message.content
            
            # è§£æJSONç»“æœ
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = content[start_idx:end_idx]
                result = json.loads(json_str)
                return {
                    'deepseek_sentiment_score': result.get('sentiment_score', 0.0),
                    'deepseek_confidence': result.get('confidence', 0.5),
                    'deepseek_sentiment_label': result.get('sentiment_label', 'ä¸­æ€§'),
                    'deepseek_market_impact': result.get('market_impact', 'ä¸­æ€§')
                }
            else:
                raise ValueError("æ— æ³•è§£æJSONå“åº”")
                
        except Exception as e:
            print(f"åˆ†æå¤±è´¥: {e}")
            return {
                'deepseek_sentiment_score': 0.0,
                'deepseek_confidence': 0.5,
                'deepseek_sentiment_label': 'ä¸­æ€§',
                'deepseek_market_impact': 'ä¸­æ€§'
            }
    
    def analyze_news_file(self, input_file: str, output_file: str = None, sample_size: int = None):
        """åˆ†ææ–°é—»æ–‡ä»¶"""
        print(f"ğŸ“° åŠ è½½æ–°é—»æ–‡ä»¶: {input_file}")
        
        # è¯»å–æ–°é—»æ•°æ®
        df = pd.read_csv(input_file)
        print(f"ğŸ“Š æ€»å…± {len(df)} æ¡æ–°é—»")
        
        # å¦‚æœæŒ‡å®šäº†æ ·æœ¬å¤§å°ï¼Œéšæœºé‡‡æ ·
        if sample_size and sample_size < len(df):
            df = df.sample(n=sample_size, random_state=42)
            print(f"ğŸ¯ éšæœºé‡‡æ · {len(df)} æ¡æ–°é—»è¿›è¡Œåˆ†æ")
        
        # ä¸ºæ¯æ¡æ–°é—»è¿›è¡Œæƒ…æ„Ÿåˆ†æ
        print("ğŸ¤– å¼€å§‹DeepSeekæƒ…æ„Ÿåˆ†æ...")
        
        results = []
        for i, row in tqdm(df.iterrows(), total=len(df), desc="åˆ†æè¿›åº¦"):
            # æ„å»ºåˆ†ææ–‡æœ¬
            text = row['title']
            if 'description' in row and pd.notna(row['description']):
                text += " " + str(row['description'])[:500]  # é™åˆ¶é•¿åº¦
            
            # åˆ†ææƒ…æ„Ÿ
            sentiment_result = self.analyze_sentiment(text)
            
            # åˆå¹¶ç»“æœ
            result_row = dict(row)
            result_row.update(sentiment_result)
            results.append(result_row)
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            time.sleep(0.1)
        
        # ä¿å­˜ç»“æœ
        results_df = pd.DataFrame(results)
        
        if output_file is None:
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            input_path = Path(input_file)
            output_file = input_path.parent / f"{input_path.stem}_with_sentiment{input_path.suffix}"
        
        results_df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"âœ… æƒ…æ„Ÿåˆ†æå®Œæˆï¼ç»“æœä¿å­˜è‡³: {output_file}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        sentiment_stats = results_df['deepseek_sentiment_score'].describe()
        print(f"\nğŸ“Š æƒ…æ„Ÿåˆ†æç»Ÿè®¡:")
        print(f"  å¹³å‡æƒ…æ„Ÿå¾—åˆ†: {sentiment_stats['mean']:.3f}")
        print(f"  æƒ…æ„Ÿå¾—åˆ†èŒƒå›´: {sentiment_stats['min']:.3f} - {sentiment_stats['max']:.3f}")
        print(f"  æ ‡å‡†å·®: {sentiment_stats['std']:.3f}")
        
        return str(output_file)

def main():
    parser = argparse.ArgumentParser(description="æ–°é—»æƒ…æ„Ÿåˆ†æ")
    parser.add_argument("input_file", help="è¾“å…¥æ–°é—»CSVæ–‡ä»¶")
    parser.add_argument("--output", "-o", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--sample", "-s", type=int, help="éšæœºé‡‡æ ·æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥API Key
    if not DEEPSEEK_API_KEY:
        print("âŒ è¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
        print("   æ–¹æ³•1: åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envæ–‡ä»¶ï¼Œæ·»åŠ : DEEPSEEK_API_KEY=your-api-key")
        print("   æ–¹æ³•2: ç›´æ¥è®¾ç½®ç¯å¢ƒå˜é‡: export DEEPSEEK_API_KEY='your-api-key'")
        return 1
    
    try:
        analyzer = NewsAnalyzer()
        analyzer.analyze_news_file(args.input_file, args.output, args.sample)
        return 0
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 