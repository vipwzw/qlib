#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeekå¤§æ¨¡å‹æƒ…æ„Ÿåˆ†æå™¨
åŸºäºDeepSeek APIè¿›è¡ŒåŠ å¯†è´§å¸æ–°é—»çš„ä¸“ä¸šæƒ…æ„Ÿåˆ†æ
"""

import os
import json
import time
import logging
import hashlib
from typing import Dict, List, Optional, Union
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import pandas as pd
import numpy as np
from tqdm import tqdm
from dotenv import load_dotenv
import openai

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æŠ‘åˆ¶OpenAIå®¢æˆ·ç«¯çš„HTTPè¯·æ±‚æ—¥å¿—
openai_logger = logging.getLogger("openai")
openai_logger.setLevel(logging.WARNING)
httpx_logger = logging.getLogger("httpx")
httpx_logger.setLevel(logging.WARNING)

# DeepSeek API é…ç½®
DEEPSEEK_LIMITS = {
    'max_context_length': 32000,
    'safe_input_tokens': 20000,
    'max_output_tokens': 4000,
    'rate_limit_per_minute': 60,
    'concurrent_requests': 5,
    'timeout_seconds': 60,
    'retry_delay': 1.0,
    'avg_tokens_per_news': 400,
}

class APICallStats:
    """ç®€åŒ–çš„APIè°ƒç”¨ç»Ÿè®¡ç±»"""
    
    def __init__(self):
        self.reset_stats()
        self.stats_lock = threading.Lock()
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡æ•°æ®"""
        self.total_calls = 0
        self.successful_calls = 0
        self.failed_calls = 0
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self.total_response_time = 0.0
    
    def record_call(self, response_time: float, input_tokens: int, output_tokens: int, success: bool):
        """è®°å½•ä¸€æ¬¡APIè°ƒç”¨"""
        with self.stats_lock:
            self.total_calls += 1
            self.total_response_time += response_time
            
            if success:
                self.successful_calls += 1
                self.total_input_tokens += input_tokens
                self.total_output_tokens += output_tokens
            else:
                self.failed_calls += 1
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_tokens = self.total_input_tokens + self.total_output_tokens
        avg_response_time = self.total_response_time / max(1, self.total_calls)
        success_rate = self.successful_calls / max(1, self.total_calls) * 100
        
        # ä¼°ç®—æˆæœ¬ (DeepSeekå®šä»·ï¼šè¾“å…¥ $0.14/1M tokens, è¾“å‡º $0.28/1M tokens)
        cost = (self.total_input_tokens * 0.14 + self.total_output_tokens * 0.28) / 1000000
        
        return {
            'total_calls': self.total_calls,
            'successful_calls': self.successful_calls,
            'failed_calls': self.failed_calls,
            'success_rate': f"{success_rate:.1f}%",
            'total_tokens': total_tokens,
            'avg_response_time': f"{avg_response_time:.2f}s",
            'estimated_cost_usd': f"${cost:.4f}",
        }
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats()
        print(f"\nğŸ“Š APIè°ƒç”¨ç»Ÿè®¡: {stats['successful_calls']}/{stats['total_calls']} æˆåŠŸç‡{stats['success_rate']}")
        print(f"ğŸ’° æ€»è®¡æˆæœ¬: {stats['estimated_cost_usd']} | â±ï¸ å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']}")

class DeepSeekSentimentAnalyzer:
    """DeepSeekæƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self, 
                 api_key: Optional[str] = None,
                 base_url: str = "https://api.deepseek.com/v1",
                 model: str = "deepseek-chat",
                 timeout: int = 30,
                 max_retries: int = 3,
                 rate_limit: float = 0.1,
                 fast_mode: bool = False):
        
        # APIé…ç½®
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        if not self.api_key:
            raise ValueError("DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–æœªæä¾›APIå¯†é’¥")
        
        self.base_url = base_url
        self.model = model
        
        # é«˜å¹¶å‘æ¨¡å¼é…ç½®ï¼ˆ100çº¿ç¨‹ä¼˜åŒ–ï¼‰
        if fast_mode:
            self.timeout = min(timeout, 15)
            self.max_retries = min(max_retries, 2)
            self.rate_limit = max(rate_limit, 0.05)
            self.max_batch_size = 50
            self.max_tokens_per_batch = 15000
        else:
            self.timeout = min(timeout, 30)
            self.max_retries = max_retries
            self.rate_limit = max(rate_limit, 0.1)
            self.max_batch_size = 30
            self.max_tokens_per_batch = DEEPSEEK_LIMITS['safe_input_tokens']
        
        # å¤šçº¿ç¨‹é…ç½®ï¼ˆæ”¯æŒå¤§è§„æ¨¡å¹¶å‘ï¼‰
        self.max_workers = 100  # 100ä¸ªçº¿ç¨‹å¹¶å‘
        
        # é…ç½®OpenAIå®¢æˆ·ç«¯
        self.client = openai.OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            timeout=self.timeout
        )
        
        # åˆå§‹åŒ–ç¼“å­˜å’Œç»Ÿè®¡
        self.cache = {}
        self.stats = APICallStats()
        
        logger.info(f"âœ… DeepSeekåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {self.model}, å¹¶å‘: {self.max_workers}çº¿ç¨‹)")

    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡"""
        # ç®€åŒ–çš„tokenä¼°ç®—ï¼šä¸­æ–‡1å­—ç¬¦â‰ˆ1tokenï¼Œè‹±æ–‡1å­—ç¬¦â‰ˆ0.25token
        chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
        other_chars = len(text) - chinese_chars
        return chinese_chars + int(other_chars * 0.25)
    
    def _build_batch_prompt(self, news_texts: List[str]) -> str:
        """æ„å»ºæ‰¹é‡åˆ†ææç¤ºè¯"""
        numbered_news = []
        for i, text in enumerate(news_texts, 1):
            numbered_news.append(f"{i}. {text}")
        
        news_list = "\n".join(numbered_news)
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹{len(news_texts)}æ¡åŠ å¯†è´§å¸æ–°é—»è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºç»“æœã€‚

åˆ†ææ ‡å‡†ï¼š
- sentiment_score: -1åˆ°1çš„æ•°å€¼ï¼ˆ-1æåº¦è´Ÿé¢ï¼Œ0ä¸­æ€§ï¼Œ1æåº¦æ­£é¢ï¼‰
- confidence: 0åˆ°1çš„ç½®ä¿¡åº¦
- sentiment_label: "è´Ÿé¢"/"ä¸­æ€§"/"æ­£é¢"
- market_impact: "åˆ©ç©º"/"ä¸­æ€§"/"åˆ©å¥½"

æ–°é—»å†…å®¹ï¼š
{news_list}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œæ¯æ¡æ–°é—»ä¸€ä¸ªå¯¹è±¡ï¼š
```json
[
  {{"id": 1, "sentiment_score": 0.5, "confidence": 0.8, "sentiment_label": "æ­£é¢", "market_impact": "åˆ©å¥½"}},
  {{"id": 2, "sentiment_score": -0.3, "confidence": 0.7, "sentiment_label": "è´Ÿé¢", "market_impact": "åˆ©ç©º"}}
]
```"""
        return prompt
    
    def _make_batch_request(self, news_texts: List[str]) -> Optional[Dict]:
        """å‘é€æ‰¹é‡è¯·æ±‚åˆ°DeepSeek API"""
        prompt = self._build_batch_prompt(news_texts)
        
        for attempt in range(self.max_retries):
            start_time = time.time()
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1,
                    max_tokens=min(4000, len(news_texts) * 200)
                )
                
                end_time = time.time()
                
                # è®°å½•ç»Ÿè®¡
                self.stats.record_call(
                    response_time=end_time - start_time,
                    input_tokens=response.usage.prompt_tokens,
                    output_tokens=response.usage.completion_tokens,
                    success=True
                )
                
                return {
                    'content': response.choices[0].message.content,
                    'usage': response.usage
                }
                
            except Exception as e:
                end_time = time.time()
                self.stats.record_call(
                    response_time=end_time - start_time,
                    input_tokens=0,
                    output_tokens=0,
                    success=False
                )
                
                if attempt < self.max_retries - 1:
                    time.sleep(self.rate_limit * (attempt + 1))
                    continue
                else:
                    logger.error(f"æ‰¹é‡è¯·æ±‚å¤±è´¥: {e}")
                    return None
        
        return None
    
    def _parse_batch_result(self, response, news_count: int) -> List[Dict]:
        """è§£ææ‰¹é‡åˆ†æç»“æœ"""
        try:
            content = response['content']
            
            # æå–JSONéƒ¨åˆ†
            start_idx = content.find('[')
            end_idx = content.rfind(']') + 1
            
            if start_idx == -1 or end_idx == 0:
                raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
            
            json_str = content[start_idx:end_idx]
            results = json.loads(json_str)
            
            # éªŒè¯å’Œå¤„ç†ç»“æœ
            processed_results = []
            for i in range(news_count):
                if i < len(results):
                    result = results[i]
                    processed_results.append({
                        'deepseek_sentiment_score': result.get('sentiment_score', 0.0),
                        'deepseek_confidence': result.get('confidence', 0.5),
                        'deepseek_sentiment_label': result.get('sentiment_label', 'ä¸­æ€§'),
                        'deepseek_market_impact': result.get('market_impact', 'ä¸­æ€§'),
                        'deepseek_key_factors': '',
                        'deepseek_reasoning': ''
                    })
                else:
                    # ç¼ºå¤±ç»“æœçš„é»˜è®¤å€¼
                    processed_results.append({
                        'deepseek_sentiment_score': 0.0,
                        'deepseek_confidence': 0.5,
                        'deepseek_sentiment_label': 'ä¸­æ€§',
                        'deepseek_market_impact': 'ä¸­æ€§',
                        'deepseek_key_factors': '',
                        'deepseek_reasoning': ''
                    })
            
            return processed_results
            
        except Exception as e:
            logger.error(f"è§£ææ‰¹é‡ç»“æœå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return [{
                'deepseek_sentiment_score': 0.0,
                'deepseek_confidence': 0.5,
                'deepseek_sentiment_label': 'ä¸­æ€§',
                'deepseek_market_impact': 'ä¸­æ€§',
                'deepseek_key_factors': '',
                'deepseek_reasoning': ''
            } for _ in range(news_count)]
    
    def analyze_batch_single_request(self, news_texts: List[str]) -> List[Dict]:
        """ä½¿ç”¨å•ä¸ªAPIè¯·æ±‚åˆ†æå¤šæ¡æ–°é—»"""
        if len(news_texts) > self.max_batch_size:
            logger.warning(f"æ‰¹é‡å¤§å°({len(news_texts)})è¶…è¿‡é™åˆ¶({self.max_batch_size})ï¼Œå°†åˆ†æ‰¹å¤„ç†")
            
            results = []
            for i in range(0, len(news_texts), self.max_batch_size):
                batch = news_texts[i:i + self.max_batch_size]
                batch_results = self.analyze_batch_single_request(batch)
                results.extend(batch_results)
            return results
        
        response = self._make_batch_request(news_texts)
        if response:
            return self._parse_batch_result(response, len(news_texts))
        else:
            logger.error("æ‰¹é‡è¯·æ±‚å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ")
            return [{
                'deepseek_sentiment_score': 0.0,
                'deepseek_confidence': 0.5,
                'deepseek_sentiment_label': 'ä¸­æ€§',
                'deepseek_market_impact': 'ä¸­æ€§',
                'deepseek_key_factors': '',
                'deepseek_reasoning': ''
            } for _ in news_texts]
    
    def _get_cache_key(self, text: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(text.encode('utf-8')).hexdigest()
    
    def analyze_single_threaded(self, text: str, thread_id: int = 0) -> Dict:
        """å•æ¡æ–°é—»åˆ†æï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        cache_key = self._get_cache_key(text)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹åŠ å¯†è´§å¸æ–°é—»è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼š

æ–°é—»å†…å®¹: {text}

è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼š
{{"sentiment_score": 0.0, "confidence": 0.8, "sentiment_label": "ä¸­æ€§", "market_impact": "ä¸­æ€§"}}"""
        
        for attempt in range(self.max_retries):
            start_time = time.time()
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1,
                    max_tokens=200
                )
                
                end_time = time.time()
                
                # è®°å½•ç»Ÿè®¡
                self.stats.record_call(
                    response_time=end_time - start_time,
                    input_tokens=response.usage.prompt_tokens,
                    output_tokens=response.usage.completion_tokens,
                    success=True
                )
                
                result = self._parse_single_result(response.choices[0].message.content)
                self.cache[cache_key] = result
                return result
        
            except Exception as e:
                end_time = time.time()
                self.stats.record_call(
                    response_time=end_time - start_time,
                    input_tokens=0,
                    output_tokens=0,
                    success=False
                )
                
                if attempt < self.max_retries - 1:
                    time.sleep(self.rate_limit)
                    continue
                else:
                    logger.error(f"çº¿ç¨‹{thread_id}åˆ†æå¤±è´¥: {e}")
                    break
            
            # é«˜å¹¶å‘æ¨¡å¼ä¸‹çš„é€Ÿç‡é™åˆ¶ï¼ˆé¿å…é˜»å¡ï¼‰
            if self.rate_limit > 0:
                time.sleep(min(self.rate_limit, 0.1))  # æœ€å¤§åªsleep 0.1ç§’
        
        # å¤±è´¥æ—¶è¿”å›é»˜è®¤ç»“æœ
        return {
            'deepseek_sentiment_score': 0.0,
            'deepseek_confidence': 0.5,
            'deepseek_sentiment_label': 'ä¸­æ€§',
            'deepseek_market_impact': 'ä¸­æ€§',
            'deepseek_key_factors': '',
            'deepseek_reasoning': ''
        }
    
    def _parse_single_result(self, content: str) -> Dict:
        """è§£æå•ä¸ªåˆ†æç»“æœ"""
        try:
            # å°è¯•è§£æJSON
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = content[start_idx:end_idx]
                result = json.loads(json_str)
                
                return {
                    'deepseek_sentiment_score': result.get('sentiment_score', 0.0),
                    'deepseek_confidence': result.get('confidence', 0.5),
                    'deepseek_sentiment_label': result.get('sentiment_label', 'ä¸­æ€§'),
                    'deepseek_market_impact': result.get('market_impact', 'ä¸­æ€§'),
                    'deepseek_key_factors': '',
                    'deepseek_reasoning': ''
                }
        except:
            pass
        
        # è§£æå¤±è´¥æ—¶è¿”å›é»˜è®¤å€¼
        return {
            'deepseek_sentiment_score': 0.0,
            'deepseek_confidence': 0.5,
            'deepseek_sentiment_label': 'ä¸­æ€§',
            'deepseek_market_impact': 'ä¸­æ€§',
            'deepseek_key_factors': '',
            'deepseek_reasoning': ''
        }
    
    def analyze_batch_multithreaded(self, texts: List[str], max_workers: Optional[int] = None) -> List[Dict]:
        """å¤šçº¿ç¨‹æ‰¹é‡åˆ†æ"""
        if not texts:
            return []
        
        max_workers = max_workers or self.max_workers
        results = [None] * len(texts)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {
                executor.submit(self.analyze_single_threaded, text, i): i 
                for i, text in enumerate(texts)
            }
            
            # æ”¶é›†ç»“æœ
            for future in tqdm(as_completed(future_to_index), total=len(texts), desc="ğŸ¤– DeepSeekåˆ†æ"):
                index = future_to_index[future]
                try:
                    results[index] = future.result()
                except Exception as e:
                    logger.error(f"çº¿ç¨‹{index}æ‰§è¡Œå¤±è´¥: {e}")
                    results[index] = {
                        'deepseek_sentiment_score': 0.0,
                        'deepseek_confidence': 0.5,
                        'deepseek_sentiment_label': 'ä¸­æ€§',
                        'deepseek_market_impact': 'ä¸­æ€§',
                        'deepseek_key_factors': '',
                        'deepseek_reasoning': ''
                    }
        
        return results
    
    def analyze_batch(self, news_data: Union[List[str], List[Dict], pd.DataFrame], 
                     title_col: str = 'title', content_col: str = 'description',
                     use_batch_request: bool = False, use_multithreading: bool = True,
                     max_workers: Optional[int] = None) -> pd.DataFrame:
        """æ‰¹é‡åˆ†ææ–°é—»æƒ…æ„Ÿ"""
        
        # æ ‡å‡†åŒ–è¾“å…¥æ•°æ®
        if isinstance(news_data, pd.DataFrame):
            df = news_data.copy()
        elif isinstance(news_data, list):
            if news_data and isinstance(news_data[0], dict):
                df = pd.DataFrame(news_data)
            else:
                df = pd.DataFrame({title_col: news_data})
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹")
        
        # æ„å»ºåˆ†ææ–‡æœ¬
        if content_col in df.columns and df[content_col].notna().any():
            texts = (df[title_col].fillna('') + ' ' + df[content_col].fillna('')).tolist()
        else:
            texts = df[title_col].fillna('').tolist()
        
        logger.info(f"å¼€å§‹åˆ†æ {len(texts)} æ¡æ–°é—»...")
        
        # æ‰§è¡Œåˆ†æ
        if use_batch_request and len(texts) <= self.max_batch_size:
            results = self.analyze_batch_single_request(texts)
        else:
            if use_multithreading:
                results = self.analyze_batch_multithreaded(texts, max_workers)
            else:
                results = [self.analyze_single_threaded(text, i) for i, text in enumerate(tqdm(texts, desc="ğŸ¤– DeepSeekåˆ†æ"))]
        
        # å°†ç»“æœæ·»åŠ åˆ°DataFrame
        results_df = pd.DataFrame(results)
        for col in results_df.columns:
            df[col] = results_df[col]
        
        logger.info(f"âœ… åˆ†æå®Œæˆï¼æˆåŠŸç‡: {self.stats.get_stats()['success_rate']}")
        return df
    
    def load_cache(self, cache_file: Optional[str] = None):
        """åŠ è½½ç¼“å­˜"""
        cache_file = cache_file or "deepseek_sentiment_cache.json"
        try:
            if os.path.exists(cache_file):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                logger.info(f"âœ… ç¼“å­˜åŠ è½½æˆåŠŸï¼Œå…± {len(self.cache)} æ¡è®°å½•")
            else:
                logger.warning(f"ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_file}")
                self.cache = {}
        except Exception as e:
            logger.warning(f"ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
            self.cache = {}
    
    def save_cache(self, cache_file: Optional[str] = None):
        """ä¿å­˜ç¼“å­˜"""
        cache_file = cache_file or "deepseek_sentiment_cache.json"
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
            logger.info(f"âœ… ç¼“å­˜ä¿å­˜æˆåŠŸï¼Œå…± {len(self.cache)} æ¡è®°å½•")
        except Exception as e:
            logger.warning(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats.get_stats()
    
    def print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats.print_stats()


def main():
    """æµ‹è¯•DeepSeekæƒ…æ„Ÿåˆ†æå™¨"""
    import sys
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # æ£€æŸ¥APIå¯†é’¥
    if not os.getenv('DEEPSEEK_API_KEY'):
        print("âš ï¸  è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
        print("    export DEEPSEEK_API_KEY='your-api-key-here'")
        return
    
    # åˆ›å»ºåˆ†æå™¨
    print("ğŸš€ åˆ›å»ºDeepSeekæƒ…æ„Ÿåˆ†æå™¨...")
    analyzer = DeepSeekSentimentAnalyzer(fast_mode=len(sys.argv) > 1 and sys.argv[1] == '--fast')
    
    # æµ‹è¯•æ•°æ®
    test_news = [
        "Bitcoin ETFè·å¾—SECæ‰¹å‡†ï¼Œæœºæ„èµ„é‡‘å¤§ä¸¾æ¶Œå…¥ã€‚ç¾å›½è¯åˆ¸äº¤æ˜“å§”å‘˜ä¼š(SEC)æ­£å¼æ‰¹å‡†äº†é¦–æ‰¹æ¯”ç‰¹å¸ç°è´§ETFï¼Œè¿™ä¸€é‡Œç¨‹ç¢‘äº‹ä»¶é¢„è®¡å°†ä¸ºåŠ å¯†è´§å¸å¸‚åœºå¸¦æ¥å¤§é‡æœºæ„èµ„é‡‘ã€‚",
        "åŠ å¯†è´§å¸äº¤æ˜“æ‰€é­é»‘å®¢æ”»å‡»ï¼ŒæŸå¤±è¶…2äº¿ç¾å…ƒã€‚å…¨çƒçŸ¥ååŠ å¯†è´§å¸äº¤æ˜“æ‰€æ˜¨æ—¥é­å—å¤§è§„æ¨¡é»‘å®¢æ”»å‡»ï¼ŒæŸå¤±é‡‘é¢è¶…è¿‡2äº¿ç¾å…ƒï¼Œå¼•å‘å¸‚åœºææ…Œæƒ…ç»ªã€‚",
        "å¤®è¡Œæ•°å­—è´§å¸ç ”å‘å–å¾—é‡å¤§è¿›å±•ã€‚ä¸­å›½äººæ°‘é“¶è¡Œå®£å¸ƒæ•°å­—äººæ°‘å¸æŠ€æœ¯ç ”å‘å–å¾—é‡å¤§çªç ´ï¼Œå°†åœ¨æ›´å¤šåŸå¸‚å¼€å±•è¯•ç‚¹åº”ç”¨ã€‚"
    ]
    
    print(f"ğŸ§ª æµ‹è¯•åˆ†æ {len(test_news)} æ¡æ–°é—»...")
    
    # åˆ†ææƒ…æ„Ÿ
    results = analyzer.analyze_batch_single_request(test_news)
    
    # æ˜¾ç¤ºç»“æœ
    print("\nğŸ“Š åˆ†æç»“æœï¼š")
    for i, (news, result) in enumerate(zip(test_news, results)):
        print(f"\n{i+1}. æ–°é—»: {news[:50]}...")
        print(f"   æƒ…æ„Ÿå¾—åˆ†: {result['deepseek_sentiment_score']}")
        print(f"   æƒ…æ„Ÿæ ‡ç­¾: {result['deepseek_sentiment_label']}")
        print(f"   ç½®ä¿¡åº¦: {result['deepseek_confidence']}")
        print(f"   å¸‚åœºå½±å“: {result['deepseek_market_impact']}")
        print(f"   å…³é”®å› ç´ : {result['deepseek_key_factors']}")
        print(f"   åˆ†æç†ç”±: {result['deepseek_reasoning']}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    analyzer.print_stats()
    
    # ä¿å­˜ç¼“å­˜
    analyzer.save_cache()
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main() 