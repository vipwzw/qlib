#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å› å­è¯„ä¼°è„šæœ¬
ç”¨äºè¯„ä¼°æ–°é—»æƒ…æ„Ÿå› å­çš„æœ‰æ•ˆæ€§
"""

import argparse
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import yaml
import logging
from typing import Dict, List, Optional
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import multiprocessing as mp
from functools import partial
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

def evaluate_single_factor(args):
    """ç‹¬ç«‹çš„å› å­è¯„ä¼°å‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹è°ƒç”¨"""
    factor_name, factor_data, returns_data = args
    
    try:
        # å»é™¤NaNå€¼
        factor_series = factor_data.dropna()
        if len(factor_series) < 50:  # æ•°æ®ç‚¹å¤ªå°‘
            return None
        
        # å¯¹é½æ•°æ®
        aligned_data = pd.concat([factor_series, returns_data], axis=1).dropna()
        if aligned_data.empty:
            return None
        
        factor_values = aligned_data.iloc[:, 0]
        return_values = aligned_data.iloc[:, 1]
        
        # è®¡ç®—ICæŒ‡æ ‡ (ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å¾ªç¯è®¡ç®—)
        ic_1d = factor_values.corr(return_values.shift(-1))
        ic_5d = factor_values.corr(return_values.shift(-5))
        
        # è®¡ç®—Rank IC
        rank_ic_1d = factor_values.rank().corr(return_values.shift(-1).rank())
        rank_ic_5d = factor_values.rank().corr(return_values.shift(-5).rank())
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        performance = {
            'factor_name': factor_name,
            'data_points': len(factor_series),
            
            # ICæŒ‡æ ‡
            'ic_1d_mean': ic_1d,
            'ic_1d_std': np.nan,  # ç®€åŒ–ç‰ˆæœ¬æš‚ä¸è®¡ç®—
            'ic_1d_ir': ic_1d,
            'ic_1d_positive_ratio': 1.0 if ic_1d > 0 else 0.0,
            
            'ic_5d_mean': ic_5d,
            'ic_5d_std': np.nan,
            'ic_5d_ir': ic_5d,
            'ic_5d_positive_ratio': 1.0 if ic_5d > 0 else 0.0,
            
            # Rank ICæŒ‡æ ‡
            'rank_ic_1d_mean': rank_ic_1d,
            'rank_ic_1d_std': np.nan,
            'rank_ic_1d_ir': rank_ic_1d,
            
            'rank_ic_5d_mean': rank_ic_5d,
            'rank_ic_5d_std': np.nan,
            'rank_ic_5d_ir': rank_ic_5d,
            
            # å› å­åŸºæœ¬ç»Ÿè®¡
            'factor_mean': factor_series.mean(),
            'factor_std': factor_series.std(),
            'factor_skew': factor_series.skew(),
            'factor_kurt': factor_series.kurtosis(),
        }
        
        return performance
        
    except Exception as e:
        print(f"è¯„ä¼°å› å­ {factor_name} æ—¶å‡ºé”™: {e}")
        return None

class FactorEvaluator:
    """å› å­è¯„ä¼°å™¨"""
    
    def __init__(self, config_path: str = "configs/config.yaml"):
        """åˆå§‹åŒ–è¯„ä¼°å™¨"""
        self.config = self._load_config(config_path)
        self._setup_logging()
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_file = project_root / config_path
        with open(config_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def load_factor_data(self, factor_path: str = None) -> pd.DataFrame:
        """åŠ è½½å› å­æ•°æ®"""
        if factor_path is None:
            # æŸ¥æ‰¾æœ€æ–°çš„å› å­æ–‡ä»¶
            factors_dir = project_root / "data" / "factors"
            if not factors_dir.exists():
                raise FileNotFoundError("å› å­æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œå› å­æ„å»º")
            
            factor_files = list(factors_dir.glob("factors_*.parquet"))
            if not factor_files:
                raise FileNotFoundError("æœªæ‰¾åˆ°å› å­æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œå› å­æ„å»º")
            
            # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
            factor_path = sorted(factor_files)[-1]
        
        self.logger.info(f"åŠ è½½å› å­æ•°æ®: {factor_path}")
        
        try:
            factors = pd.read_parquet(factor_path)
            self.logger.info(f"æˆåŠŸåŠ è½½å› å­æ•°æ®ï¼Œå½¢çŠ¶: {factors.shape}")
            return factors
        except Exception as e:
            self.logger.error(f"åŠ è½½å› å­æ•°æ®å¤±è´¥: {e}")
            raise
    
    def load_returns_data(self) -> pd.Series:
        """åŠ è½½æ”¶ç›Šç‡æ•°æ®"""
        self.logger.info("ä»ä»·æ ¼æ•°æ®è®¡ç®—çœŸå®æ”¶ç›Šç‡...")
        
        try:
            # åŠ è½½æœ€æ–°çš„ä»·æ ¼æ•°æ®
            import glob
            price_files = glob.glob(str(project_root / "data" / "raw" / "price" / "*.csv"))
            if price_files:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
                import os
                latest_price_file = sorted(price_files, key=os.path.getmtime)[-1]
                self.logger.info(f"åŠ è½½ä»·æ ¼æ•°æ®: {latest_price_file}")
                
                price_data = pd.read_csv(latest_price_file)
                price_data['timestamp'] = pd.to_datetime(price_data['timestamp'])
                price_data.set_index('timestamp', inplace=True)
                
                # è®¡ç®—1åˆ†é’Ÿæ”¶ç›Šç‡
                returns = price_data['close'].pct_change().dropna()
                
                self.logger.info(f"è®¡ç®—å¾—åˆ° {len(returns)} ä¸ªæ”¶ç›Šç‡æ•°æ®ç‚¹")
                self.logger.info(f"æ”¶ç›Šç‡æ—¶é—´èŒƒå›´: {returns.index.min()} åˆ° {returns.index.max()}")
                
                return returns
            else:
                # å¦‚æœæ²¡æœ‰ä»·æ ¼æ•°æ®ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ä½†ä½¿ç”¨æ­£ç¡®çš„æ—¶é—´èŒƒå›´
                self.logger.warning("æœªæ‰¾åˆ°ä»·æ ¼æ•°æ®ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ”¶ç›Šç‡æ•°æ®...")
                dates = pd.date_range(start='2025-06-07', end='2025-07-07', freq='min')
                np.random.seed(42)
                returns = np.random.normal(0.0001, 0.005, len(dates))  # åˆ†é’Ÿæ”¶ç›Šç‡
                return pd.Series(returns, index=dates, name='returns')
                
        except Exception as e:
            self.logger.error(f"åŠ è½½æ”¶ç›Šç‡æ•°æ®å¤±è´¥: {e}")
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ä½œä¸ºåå¤‡
            dates = pd.date_range(start='2025-06-07', end='2025-07-07', freq='min')
            np.random.seed(42)
            returns = np.random.normal(0.0001, 0.005, len(dates))
            return pd.Series(returns, index=dates, name='returns')
    
    def calculate_ic(self, factor: pd.Series, returns: pd.Series, periods: int = 1) -> pd.Series:
        """è®¡ç®—ä¿¡æ¯ç³»æ•°(IC)"""
        # å¯¹é½æ•°æ®
        aligned_data = pd.concat([factor, returns], axis=1).dropna()
        
        if aligned_data.empty:
            self.logger.warning("å› å­å’Œæ”¶ç›Šç‡æ•°æ®æ— æ³•å¯¹é½")
            return pd.Series(dtype=float)
        
        factor_values = aligned_data.iloc[:, 0]
        return_values = aligned_data.iloc[:, 1].shift(-periods)
        
        # è®¡ç®—æ»šåŠ¨IC
        ic_values = []
        window = 30  # 30å¤©æ»šåŠ¨çª—å£
        
        for i in range(window, len(factor_values)):
            factor_window = factor_values.iloc[i-window:i]
            return_window = return_values.iloc[i-window:i]
            
            if len(factor_window.dropna()) > 10 and len(return_window.dropna()) > 10:
                ic = factor_window.corr(return_window)
                ic_values.append(ic)
            else:
                ic_values.append(np.nan)
        
        ic_index = factor_values.index[window:]
        return pd.Series(ic_values, index=ic_index, name=f'IC_{periods}d')
    
    def calculate_rank_ic(self, factor: pd.Series, returns: pd.Series, periods: int = 1) -> pd.Series:
        """è®¡ç®—Rank IC"""
        # å¯¹é½æ•°æ®
        aligned_data = pd.concat([factor, returns], axis=1).dropna()
        
        if aligned_data.empty:
            return pd.Series(dtype=float)
        
        factor_values = aligned_data.iloc[:, 0]
        return_values = aligned_data.iloc[:, 1].shift(-periods)
        
        # è®¡ç®—æ»šåŠ¨Rank IC
        rank_ic_values = []
        window = 30
        
        for i in range(window, len(factor_values)):
            factor_window = factor_values.iloc[i-window:i]
            return_window = return_values.iloc[i-window:i]
            
            if len(factor_window.dropna()) > 10 and len(return_window.dropna()) > 10:
                factor_rank = factor_window.rank()
                return_rank = return_window.rank()
                rank_ic = factor_rank.corr(return_rank)
                rank_ic_values.append(rank_ic)
            else:
                rank_ic_values.append(np.nan)
        
        rank_ic_index = factor_values.index[window:]
        return pd.Series(rank_ic_values, index=rank_ic_index, name=f'RankIC_{periods}d')
    
    def factor_performance_summary(self, factor_name: str, factor_data: pd.Series, returns_data: pd.Series) -> Dict:
        """è®¡ç®—å› å­è¡¨ç°æ±‡æ€»"""
        self.logger.info(f"è¯„ä¼°å› å­: {factor_name}")
        
        # è®¡ç®—ICæŒ‡æ ‡
        ic_1d = self.calculate_ic(factor_data, returns_data, 1)
        ic_5d = self.calculate_ic(factor_data, returns_data, 5)
        
        rank_ic_1d = self.calculate_rank_ic(factor_data, returns_data, 1)
        rank_ic_5d = self.calculate_rank_ic(factor_data, returns_data, 5)
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        performance = {
            'factor_name': factor_name,
            'data_points': len(factor_data),
            
            # ICæŒ‡æ ‡
            'ic_1d_mean': ic_1d.mean(),
            'ic_1d_std': ic_1d.std(),
            'ic_1d_ir': ic_1d.mean() / ic_1d.std() if ic_1d.std() > 0 else 0,
            'ic_1d_positive_ratio': (ic_1d > 0).mean(),
            
            'ic_5d_mean': ic_5d.mean(),
            'ic_5d_std': ic_5d.std(),
            'ic_5d_ir': ic_5d.mean() / ic_5d.std() if ic_5d.std() > 0 else 0,
            'ic_5d_positive_ratio': (ic_5d > 0).mean(),
            
            # Rank ICæŒ‡æ ‡
            'rank_ic_1d_mean': rank_ic_1d.mean(),
            'rank_ic_1d_std': rank_ic_1d.std(),
            'rank_ic_1d_ir': rank_ic_1d.mean() / rank_ic_1d.std() if rank_ic_1d.std() > 0 else 0,
            
            'rank_ic_5d_mean': rank_ic_5d.mean(),
            'rank_ic_5d_std': rank_ic_5d.std(),
            'rank_ic_5d_ir': rank_ic_5d.mean() / rank_ic_5d.std() if rank_ic_5d.std() > 0 else 0,
            
            # å› å­åŸºæœ¬ç»Ÿè®¡
            'factor_mean': factor_data.mean(),
            'factor_std': factor_data.std(),
            'factor_skew': factor_data.skew(),
            'factor_kurt': factor_data.kurtosis(),
        }
        
        return performance
    
    def evaluate_all_factors(self, factors_df: pd.DataFrame, returns_data: pd.Series, n_jobs: int = None) -> pd.DataFrame:
        """è¯„ä¼°æ‰€æœ‰å› å­ï¼ˆæ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œï¼‰"""
        if n_jobs is None:
            n_jobs = min(mp.cpu_count(), len(factors_df.columns))
        
        self.logger.info(f"å¼€å§‹è¯„ä¼°æ‰€æœ‰å› å­... (ä½¿ç”¨ {n_jobs} ä¸ªè¿›ç¨‹)")
        
        # å‡†å¤‡å‚æ•°
        factor_args = [(factor_name, factors_df[factor_name], returns_data) 
                      for factor_name in factors_df.columns]
        
        results = []
        
        if n_jobs == 1:
            # å•è¿›ç¨‹æ‰§è¡Œï¼ˆå¸¦è¿›åº¦æ¡ï¼‰
            for args in tqdm(factor_args, desc="è¯„ä¼°å› å­", ncols=80):
                result = evaluate_single_factor(args)
                if result is not None:
                    results.append(result)
        else:
            # å¤šè¿›ç¨‹æ‰§è¡Œ
            with mp.Pool(processes=n_jobs) as pool:
                # ä½¿ç”¨imapæ˜¾ç¤ºè¿›åº¦
                results_iter = pool.imap(evaluate_single_factor, factor_args)
                
                # å¸¦è¿›åº¦æ¡æ”¶é›†ç»“æœ
                for result in tqdm(results_iter, total=len(factor_args), 
                                 desc="è¯„ä¼°å› å­", ncols=80):
                    if result is not None:
                        results.append(result)
        
        if results:
            results_df = pd.DataFrame(results)
            results_df = results_df.set_index('factor_name')
            self.logger.info(f"æˆåŠŸè¯„ä¼°äº† {len(results_df)} ä¸ªå› å­")
            return results_df
        else:
            self.logger.warning("æ²¡æœ‰æˆåŠŸè¯„ä¼°ä»»ä½•å› å­")
            return pd.DataFrame()
    
    def print_evaluation_results(self, results_df: pd.DataFrame):
        """æ‰“å°è¯„ä¼°ç»“æœ"""
        if results_df.empty:
            print("æ²¡æœ‰å¯æ˜¾ç¤ºçš„è¯„ä¼°ç»“æœ")
            return
        
        print("\n" + "="*60)
        print("å› å­è¯„ä¼°ç»“æœ")
        print("="*60)
        
        # æŒ‰IC_IRæ’åº
        sorted_results = results_df.sort_values('ic_1d_ir', ascending=False)
        
        for factor_name, row in sorted_results.iterrows():
            print(f"\nå› å­åç§°: {factor_name}")
            print("-" * 40)
            print(f"1æ—¥ICå‡å€¼: {row['ic_1d_mean']:.4f}")
            print(f"1æ—¥ICæ ‡å‡†å·®: {row['ic_1d_std']:.4f}")
            print(f"1æ—¥IC_IR: {row['ic_1d_ir']:.4f}")
            print(f"1æ—¥æ­£ICæ¯”ä¾‹: {row['ic_1d_positive_ratio']:.2%}")
            print(f"5æ—¥ICå‡å€¼: {row['ic_5d_mean']:.4f}")
            print(f"5æ—¥IC_IR: {row['ic_5d_ir']:.4f}")
            print(f"å› å­å‡å€¼: {row['factor_mean']:.4f}")
            print(f"å› å­æ ‡å‡†å·®: {row['factor_std']:.4f}")
    
    def generate_evaluation_report(self, results_df: pd.DataFrame, output_path: str = None):
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = project_root / "data" / "results" / f"factor_evaluation_report_{timestamp}.html"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_content = self._generate_html_report(results_df)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        self.logger.info(f"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")
    
    def _generate_html_report(self, results_df: pd.DataFrame) -> str:
        """ç”ŸæˆHTMLæŠ¥å‘Šå†…å®¹"""
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>å› å­è¯„ä¼°æŠ¥å‘Š</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                table { border-collapse: collapse; width: 100%; margin: 20px 0; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: right; }
                th { background-color: #f2f2f2; font-weight: bold; }
                .header { text-align: center; color: #333; }
                .summary { background-color: #f9f9f9; padding: 15px; margin: 20px 0; border-radius: 5px; }
            </style>
        </head>
        <body>
            <h1 class="header">æ–°é—»æƒ…æ„Ÿå› å­è¯„ä¼°æŠ¥å‘Š</h1>
            <div class="summary">
                <h3>è¯„ä¼°æ‘˜è¦</h3>
                <p>è¯„ä¼°æ—¶é—´: """ + datetime.now().strftime("%Y-%m-%d %H:%M:%S") + """</p>
                <p>è¯„ä¼°å› å­æ•°é‡: """ + str(len(results_df)) + """</p>
                <p>æœ€ä½³å› å­(æŒ‰1æ—¥IC_IR): """ + (results_df.sort_values('ic_1d_ir', ascending=False).index[0] if not results_df.empty else "æ— ") + """</p>
            </div>
            
            <h2>è¯¦ç»†ç»“æœ</h2>
            """ + results_df.round(4).to_html() + """
            
        </body>
        </html>
        """
        return html
    
    def save_results(self, results_df: pd.DataFrame, filename: str = None):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"factor_evaluation_{timestamp}.csv"
        
        results_dir = project_root / "data" / "results"
        results_dir.mkdir(parents=True, exist_ok=True)
        
        filepath = results_dir / filename
        results_df.to_csv(filepath)
        
        self.logger.info(f"è¯„ä¼°ç»“æœå·²ä¿å­˜è‡³: {filepath}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å› å­è¯„ä¼°å·¥å…· (æ”¯æŒå¤šæ ¸å¿ƒå¹¶è¡Œ)")
    parser.add_argument("--config", default="configs/config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--factor-path", help="å› å­æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--factor", help="è¯„ä¼°ç‰¹å®šå› å­åç§°")
    parser.add_argument("--generate-report", action="store_true", help="ç”ŸæˆHTMLæŠ¥å‘Š")
    parser.add_argument("--save-results", action="store_true", help="ä¿å­˜è¯„ä¼°ç»“æœ")
    parser.add_argument("--n-jobs", type=int, default=None, 
                       help=f"å¹¶è¡Œè¿›ç¨‹æ•° (é»˜è®¤: min(CPUæ ¸å¿ƒæ•°={mp.cpu_count()}, å› å­æ•°))")
    parser.add_argument("--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†è¯„ä¼°ç»“æœ")
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–è¯„ä¼°å™¨
        evaluator = FactorEvaluator(args.config)
        
        # åŠ è½½æ•°æ®
        print("ğŸ” æ­£åœ¨åŠ è½½æ•°æ®...")
        factors_df = evaluator.load_factor_data(args.factor_path)
        returns_data = evaluator.load_returns_data()
        
        print(f"ğŸ“Š å› å­æ•°é‡: {len(factors_df.columns)}")
        print(f"ğŸ’» å¯ç”¨CPUæ ¸å¿ƒæ•°: {mp.cpu_count()}")
        
        if args.factor:
            # è¯„ä¼°ç‰¹å®šå› å­
            if args.factor not in factors_df.columns:
                print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å› å­ '{args.factor}'")
                print(f"ğŸ“‹ å¯ç”¨å› å­: {list(factors_df.columns)}")
                return 1
            
            factor_series = factors_df[args.factor]
            performance = evaluator.factor_performance_summary(args.factor, factor_series, returns_data)
            
            # æ‰“å°å•ä¸ªå› å­ç»“æœ
            print("\n" + "="*50)
            print(f"å› å­è¯„ä¼°ç»“æœ: {args.factor}")
            print("="*50)
            for key, value in performance.items():
                if key != 'factor_name':
                    print(f"{key}: {value:.4f}")
        else:
            # è¯„ä¼°æ‰€æœ‰å› å­
            n_jobs = args.n_jobs if args.n_jobs else min(mp.cpu_count(), len(factors_df.columns))
            print(f"ğŸš€ å¼€å§‹å¹¶è¡Œè¯„ä¼° (è¿›ç¨‹æ•°: {n_jobs})")
            
            results_df = evaluator.evaluate_all_factors(factors_df, returns_data, n_jobs=n_jobs)
            
            if not results_df.empty:
                print(f"\nâœ… æˆåŠŸè¯„ä¼°äº† {len(results_df)} ä¸ªå› å­")
                
                # æ˜¾ç¤ºTOPå› å­
                top_factors = results_df.sort_values('ic_1d_ir', ascending=False, na_position='last').head()
                print("\nğŸ† TOP 5 å› å­ (æŒ‰1æ—¥IC_IRæ’åº):")
                for i, (factor_name, row) in enumerate(top_factors.iterrows(), 1):
                    ic_ir = row['ic_1d_ir']
                    ic_mean = row['ic_1d_mean']
                    if pd.notna(ic_ir) and pd.notna(ic_mean):
                        print(f"  {i}. {factor_name}: IC_IR={ic_ir:.4f}, IC={ic_mean:.4f}")
                    else:
                        print(f"  {i}. {factor_name}: IC_IR=nan, IC=nan")
                
                # æ‰“å°è¯¦ç»†ç»“æœï¼ˆå¯é€‰ï¼‰
                if args.verbose:
                    evaluator.print_evaluation_results(results_df)
                
                # ç”ŸæˆæŠ¥å‘Š
                if args.generate_report:
                    evaluator.generate_evaluation_report(results_df)
                    print("ğŸ“„ HTMLæŠ¥å‘Šå·²ç”Ÿæˆ")
                
                # ä¿å­˜ç»“æœ
                if args.save_results:
                    evaluator.save_results(results_df)
                    print("ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°CSV")
            else:
                print("âŒ æœªèƒ½ç”Ÿæˆä»»ä½•è¯„ä¼°ç»“æœ")
        
        print("\nğŸ‰ å› å­è¯„ä¼°å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å› å­è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 